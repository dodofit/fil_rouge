{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorianfitton/opt/anaconda3/envs/bgd/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/Users/dorianfitton/opt/anaconda3/envs/bgd/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer csv already exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/examples/datasets/EPEX_FR_2_transformer.csv'):\n",
    "\n",
    "    df = pd.read_csv(\"/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/examples/datasets/EPEX_FR_NEW_UTC.csv\")\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    # Create features for positional encoding \n",
    "    df['Hour of the day'] = df['Date'].dt.hour\n",
    "    df['Day of the week'] = df['Date'].dt.dayofweek\n",
    "    df['Day of the year'] = df['Date'].dt.dayofyear\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month of the year'] = df['Date'].dt.month\n",
    "    print(df.head())\n",
    "\n",
    "    df.to_csv(\"/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/examples/datasets/EPEX_FR_2_transformer.csv\")\n",
    "    print(\"CSV done and saved\")\n",
    "\n",
    "else:\n",
    "    print(\"Transformer csv already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Load forecast</th>\n",
       "      <th>Generation forecast</th>\n",
       "      <th>Price</th>\n",
       "      <th>Hour of the day</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Day of the year</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month of the year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>73650.0</td>\n",
       "      <td>69539.0</td>\n",
       "      <td>58.23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>72350.0</td>\n",
       "      <td>67376.0</td>\n",
       "      <td>51.95</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>68750.0</td>\n",
       "      <td>65412.0</td>\n",
       "      <td>47.27</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>65900.0</td>\n",
       "      <td>64557.0</td>\n",
       "      <td>45.49</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>64552.0</td>\n",
       "      <td>44.50</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                Date  Load forecast  Generation forecast  Price  \\\n",
       "0           0 2017-01-01 00:00:00        73650.0              69539.0  58.23   \n",
       "1           1 2017-01-01 01:00:00        72350.0              67376.0  51.95   \n",
       "2           2 2017-01-01 02:00:00        68750.0              65412.0  47.27   \n",
       "3           3 2017-01-01 03:00:00        65900.0              64557.0  45.49   \n",
       "4           4 2017-01-01 04:00:00        65000.0              64552.0  44.50   \n",
       "\n",
       "   Hour of the day  Day of the week  Day of the year  Year  Month of the year  \n",
       "0                0                6                1  2017                  1  \n",
       "1                1                6                1  2017                  1  \n",
       "2                2                6                1  2017                  1  \n",
       "3                3                6                1  2017                  1  \n",
       "4                4                6                1  2017                  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/examples/datasets/EPEX_FR_2_transformer.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "dataset = Dataset.from_pandas(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres \n",
    "nb_time_feat = 7\n",
    "context = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9866336c3f5d48729a3aaf7cf043da2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Séparation du dataset en données de test et train (pas nécessaire)\n",
    "train_dataset = dataset.filter(lambda x: x['Date'].year < 2021)\n",
    "#test_dataset = dataset.filter(lambda x: x['Date'].date() == pd.to_datetime('2021-01-01').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793021747af74e3d8fd048edc1b76b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/35064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_dataset shape:  (2160, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff9285985104ab2b016fd05381a80ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/35064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future_dataset shape:  (24, 10)\n"
     ]
    }
   ],
   "source": [
    "# On fait la prédiction à partir de la première date \n",
    "date = train_dataset['Date'][24*context].date()\n",
    "\n",
    "# On sépare les données d'entrainement et les données de test (ici on a un jour de test)\n",
    "\n",
    "past_dataset = train_dataset.filter(lambda x: x['Date'].date() < date)\n",
    "print(\"past_dataset shape: \", past_dataset.shape)\n",
    "\n",
    "future_dataset = train_dataset.filter(lambda x: x['Date'].date() == date)\n",
    "print(\"future_dataset shape: \", future_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_observed_mask shape: torch.Size([1, 2160])\n"
     ]
    }
   ],
   "source": [
    "# On définit quelles vont être les données utilisées/suprimées pour l'entrainement en utilisant un masque (en cas de données manquantes / NaN)\n",
    "past_observed_mask = torch.ones(24*context).reshape(1, -1)\n",
    "print(\"past_observed_mask shape:\",past_observed_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features shape: torch.Size([1, 2160, 7])\n",
      "future_time_features shape: torch.Size([1, 24, 7])\n"
     ]
    }
   ],
   "source": [
    "# On définit la matrice des features (variables exogènes et positional encoding) sur les données d'entrainement et les données de test\n",
    "\n",
    "past_time_features = torch.tensor(list(zip(past_dataset['Day of the week'],\n",
    "                                           past_dataset['Hour of the day'],\n",
    "                                           past_dataset['Day of the year'],\n",
    "                                           past_dataset['Year'],\n",
    "                                           past_dataset['Month of the year'],\n",
    "                                           past_dataset['Load forecast'],\n",
    "                                           past_dataset['Generation forecast'])))\\\n",
    "                                          .reshape(1, -1, nb_time_feat)\n",
    "\n",
    "print(\"past_time_features shape:\", past_time_features.shape)\n",
    "\n",
    "future_time_features = torch.tensor(list(zip(future_dataset['Day of the week'],\n",
    "                                             future_dataset['Hour of the day'],\n",
    "                                             future_dataset['Day of the year'],\n",
    "                                             future_dataset['Year'],\n",
    "                                             future_dataset['Month of the year'],\n",
    "                                             future_dataset['Load forecast'],\n",
    "                                             future_dataset['Generation forecast'])))\\\n",
    "                                             .reshape(1, -1, nb_time_feat)\n",
    "print(\"future_time_features shape:\",future_time_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_values shape: torch.Size([1, 2160])\n",
      "future_values shape: torch.Size([1, 24])\n"
     ]
    }
   ],
   "source": [
    "# On définit les valeurs de la variable endogène pour les données d'entrainement et pour les données de test\n",
    "\n",
    "past_values = torch.tensor(past_dataset['Price']).reshape(1, -1)\n",
    "print(\"past_values shape:\",past_values.shape)\n",
    "\n",
    "future_values = torch.tensor(future_dataset['Price']).reshape(1, -1)\n",
    "print(\"future_values shape:\",future_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features shape: torch.Size([1, 2160, 7])\n",
      "past_values shape: torch.Size([1, 2160])\n",
      "past_observed_mask shape: torch.Size([1, 2160])\n",
      "future_time_features shape: torch.Size([1, 24, 7])\n",
      "future_values shape: torch.Size([1, 24])\n"
     ]
    }
   ],
   "source": [
    "# On transfert les matrices vers le gpu \n",
    "past_values = past_values.to(device)\n",
    "past_time_features = past_time_features.to(device)\n",
    "past_observed_mask = past_observed_mask.to(device)\n",
    "future_values = future_values.to(device)\n",
    "future_time_features = future_time_features.to(device)\n",
    "\n",
    "print(\"past_time_features shape:\", past_time_features.shape)\n",
    "print(\"past_values shape:\",past_values.shape)\n",
    "print(\"past_observed_mask shape:\",past_observed_mask.shape)\n",
    "\n",
    "print(\"future_time_features shape:\",future_time_features.shape)\n",
    "print(\"future_values shape:\",future_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Time Series Transformer configuration with 24 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length   = 24, \n",
    "                                            context_length      = 24 * (context-1) + 17, \n",
    "                                            input_size          = 1, \n",
    "                                            output_size         = 1, \n",
    "                                            num_time_features   = nb_time_feat )\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTSPredictionOutput(loss=tensor(5.2091, grad_fn=<DivBackward0>), params=(tensor([[2.9365, 2.9245, 2.9067, 2.9391, 2.9028, 2.9107, 2.9167, 2.9190, 2.9258,\n",
       "         2.9551, 2.9528, 2.9383, 2.8823, 2.9302, 2.9564, 2.9168, 2.9268, 2.9012,\n",
       "         2.9575, 2.9761, 2.9372, 2.9155, 2.9449, 2.9032]],\n",
       "       grad_fn=<SqueezeBackward1>), tensor([[ 0.0367,  0.0685,  0.0088, -0.0140, -0.0127,  0.0984,  0.0115,  0.0304,\n",
       "         -0.0843,  0.0030,  0.0137,  0.0896, -0.0250,  0.0402, -0.1098,  0.0136,\n",
       "          0.0586, -0.0508, -0.0627,  0.0188,  0.0389,  0.0467,  0.0518,  0.0420]],\n",
       "       grad_fn=<SqueezeBackward1>), tensor([[0.9852, 1.0062, 1.0155, 0.9845, 0.9973, 0.9678, 1.0014, 0.9995, 0.9982,\n",
       "         0.9987, 1.0161, 0.9935, 0.9873, 0.9437, 0.9712, 0.9854, 1.0272, 1.0164,\n",
       "         0.9724, 0.9996, 0.9877, 0.9969, 0.9831, 0.9773]],\n",
       "       grad_fn=<SqueezeBackward1>)), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 7.2905e-01,  7.5847e-01, -1.2919e+00,  ...,  1.0411e+00,\n",
       "           3.6434e-02, -1.1606e-04],\n",
       "         [ 7.3543e-01,  7.1736e-01, -1.2881e+00,  ...,  1.0382e+00,\n",
       "           8.1443e-02, -1.9688e+00],\n",
       "         [ 7.6524e-01,  7.9990e-01, -1.1868e+00,  ...,  1.0680e+00,\n",
       "           9.5856e-02, -1.8041e+00],\n",
       "         ...,\n",
       "         [ 8.7028e-01,  7.9279e-01, -1.2521e+00,  ...,  1.1506e+00,\n",
       "           1.9525e-01, -1.8431e+00],\n",
       "         [ 8.5133e-01,  7.5544e-01, -1.3045e+00,  ...,  1.3357e-02,\n",
       "           1.4536e-01, -1.9099e+00],\n",
       "         [ 8.9807e-01,  7.6552e-01, -1.3489e+00,  ...,  1.1854e+00,\n",
       "           1.3342e-01, -2.0695e+00]]], grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None, loc=tensor([[0.]]), scale=tensor([[54.9910]]), static_features=tensor([[0.0000, 4.0072]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_time_features=future_time_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.782734</td>\n",
       "      <td>-26.099804</td>\n",
       "      <td>-3.193981</td>\n",
       "      <td>-14.078363</td>\n",
       "      <td>-12.001953</td>\n",
       "      <td>-3.627244</td>\n",
       "      <td>-12.409479</td>\n",
       "      <td>-21.700716</td>\n",
       "      <td>-15.958526</td>\n",
       "      <td>0.644061</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341909</td>\n",
       "      <td>14.395869</td>\n",
       "      <td>4.388855</td>\n",
       "      <td>-2.381189</td>\n",
       "      <td>-19.363369</td>\n",
       "      <td>3.30722</td>\n",
       "      <td>-28.608604</td>\n",
       "      <td>-3.585922</td>\n",
       "      <td>5.668192</td>\n",
       "      <td>0.359775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2          3          4         5          6   \\\n",
       "0 -13.782734 -26.099804 -3.193981 -14.078363 -12.001953 -3.627244 -12.409479   \n",
       "\n",
       "          7          8         9   ...        14         15        16  \\\n",
       "0 -21.700716 -15.958526  0.644061  ... -1.341909  14.395869  4.388855   \n",
       "\n",
       "         17         18       19         20        21        22        23  \n",
       "0 -2.381189 -19.363369  3.30722 -28.608604 -3.585922  5.668192  0.359775  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_prediction = outputs.sequences.mean(dim=1).detach().cpu()\n",
    "df_pred = pd.DataFrame(mean_prediction.numpy())\n",
    "df_pred\n",
    "\n",
    "#df_pred.to_csv('/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/forecasts/transformer_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerForPrediction(\n",
       "  (model): TimeSeriesTransformerModel(\n",
       "    (scaler): TimeSeriesMeanScaler()\n",
       "    (encoder): TimeSeriesTransformerEncoder(\n",
       "      (value_embedding): TimeSeriesValueEmbedding(\n",
       "        (value_projection): Linear(in_features=16, out_features=64, bias=False)\n",
       "      )\n",
       "      (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(2177, 64)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TimeSeriesTransformerEncoderLayer(\n",
       "          (self_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TimeSeriesTransformerDecoder(\n",
       "      (value_embedding): TimeSeriesValueEmbedding(\n",
       "        (value_projection): Linear(in_features=16, out_features=64, bias=False)\n",
       "      )\n",
       "      (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(2177, 64)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TimeSeriesTransformerDecoderLayer(\n",
       "          (self_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (parameter_projection): ParameterProjection(\n",
       "    (proj): ModuleList(\n",
       "      (0-2): 3 x Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (domain_map): LambdaLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerForPrediction\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"kashif/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction.from_pretrained(\n",
    "    \"huggingface/time-series-transformer-tourism-monthly\"\n",
    ")\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 61, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch['past_time_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_ff, input_sequence_length, output_sequence_length, dropout_rate):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(3, d_model)  # Change the input dimension to 3\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(num_heads, d_model, d_ff, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(num_heads, d_model, d_ff, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(d_model, output_sequence_length)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.double()  # Convert input to DoubleTensor\n",
    "        input_embedding = self.embedding(input.float())  # Convert input to FloatTensor\n",
    "        input_embedding = self.positional_encoding(input_embedding)\n",
    "\n",
    "        enc_output = input_embedding\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_output = encoder_layer(enc_output)\n",
    "\n",
    "        dec_output = enc_output\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            dec_output = decoder_layer(dec_output, enc_output)\n",
    "\n",
    "        output = self.output_layer(dec_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, d_ff, dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiheadAttention(num_heads, d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attention = self.self_attention(x, x, x)\n",
    "        attention = self.dropout1(attention)\n",
    "        x = self.norm1(x + attention)\n",
    "        \n",
    "        ff = self.feed_forward(x)\n",
    "        ff = self.dropout2(ff)\n",
    "        x = self.norm2(x + ff)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, d_ff, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiheadAttention(num_heads, d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.encoder_attention = MultiheadAttention(num_heads, d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, enc_output):\n",
    "        self_attention = self.self_attention(x, x, x)\n",
    "        self_attention = self.dropout1(self_attention)\n",
    "        x = self.norm1(x + self_attention)\n",
    "        \n",
    "        encoder_attention = self.encoder_attention(x, enc_output, enc_output)\n",
    "        encoder_attention = self.dropout2(encoder_attention)\n",
    "        x = self.norm2(x + encoder_attention)\n",
    "        \n",
    "        ff = self.feed_forward(x)\n",
    "        ff = self.dropout3(ff)\n",
    "        x = self.norm3(x + ff)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.output = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, query, key, value):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        query = self.query(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key = self.key(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        value = self.value(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        attention_weights = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "        \n",
    "        output = torch.matmul(attention_weights, value)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        output = self.output(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        position = torch.arange(0, max_sequence_length).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe = torch.zeros(max_sequence_length, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52584, 3)\n",
      "torch.Size([1, 52584, 3])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "num_layers = 2\n",
    "d_model = 16\n",
    "num_heads = 8 \n",
    "d_ff = 64\n",
    "input_sequence_length = 5*24\n",
    "output_sequence_length = 24\n",
    "dropout_rate = 0.2\n",
    "device = torch.device('cpu')\n",
    "model = TransformerModel(num_layers, d_model, num_heads, d_ff, input_sequence_length, output_sequence_length, dropout_rate).to(device)\n",
    "#model.load_state_dict(torch.load('path_to_saved_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "array_data = np.array(df.loc[:,['Price', 'Load forecast', 'Generation forecast']])\n",
    "print(array_data.shape)\n",
    "# Prepare the input data for prediction\n",
    "input_data = torch.tensor(array_data)  # input_sequence should be of shape (k,)\n",
    "input_data = input_data.unsqueeze(0).to(device)  # Add batch dimension (1, k)\n",
    "print(input_data.shape)\n",
    "\n",
    "# Perform the prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_data)\n",
    "\n",
    "# Extract the predicted output\n",
    "predicted_output = output.squeeze(0)  # Remove the batch dimension (1, m) -> (m,)\n",
    "\n",
    "# Interpret the predicted output\n",
    "predicted_prices = predicted_output.numpy()  # Convert to NumPy array\n",
    "predicted_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frtr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
