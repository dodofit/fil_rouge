{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd \n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relativedelta\n",
    "\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/examples/datasets/EPEX_FR_2_transformer.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Hour of the day'] = df['Date'].dt.hour\n",
    "df['Day of the week'] = df['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Date  Load forecast  Generation forecast  Price   \n",
      "0 2017-01-01 00:00:00        73650.0              69539.0  58.23  \\\n",
      "1 2017-01-01 01:00:00        72350.0              67376.0  51.95   \n",
      "2 2017-01-01 02:00:00        68750.0              65412.0  47.27   \n",
      "3 2017-01-01 03:00:00        65900.0              64557.0  45.49   \n",
      "4 2017-01-01 04:00:00        65000.0              64552.0  44.50   \n",
      "\n",
      "   Hour of the day  Day of the week  \n",
      "0                0                6  \n",
      "1                1                6  \n",
      "2                2                6  \n",
      "3                3                6  \n",
      "4                4                6  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/infres/dfitton-21/pfr/fil_rouge/examples/datasets/EPEX_FR 2.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Hour of the day'] = df['Date'].dt.hour\n",
    "df['Day of the week'] = df['Date'].dt.dayofweek\n",
    "print(df.head())\n",
    "\n",
    "window = 1 # 1 year\n",
    "context_length = 24*30 # 1 week\n",
    "pred_date = pd.to_datetime('2021-01-01')\n",
    "df['Date'].iloc[0] + pd.Timedelta(hours=context_length)\n",
    "date_range = pd.date_range(start=pred_date-relativedelta(years=1)+ pd.Timedelta(hours=context_length), end=pred_date-pd.Timedelta(hours=1), freq='d')\n",
    "\n",
    "Dataset_ = {'past_values':[], 'future_values':[], 'past_time_features':[], 'future_time_features':[], 'past_observed_mask':[]}\n",
    "\n",
    "for date in date_range:\n",
    "    mask_date_context = (df['Date'] >= date-relativedelta(hours=context_length)) & (df['Date'] < date)\n",
    "    mask_date_pred = (df['Date'] >= date) & (df['Date'] < date+relativedelta(hours=24))\n",
    "    past_values = torch.tensor(df['Price'][mask_date_context].values)\n",
    "    future_values = torch.tensor(df['Price'].loc[mask_date_pred].values)\n",
    "\n",
    "    past_time_features = torch.tensor(df[['Hour of the day', 'Day of the week', 'Load forecast', 'Generation forecast']][mask_date_context].values)\n",
    "    future_time_features = torch.tensor(df[['Hour of the day', 'Day of the week', 'Load forecast', 'Generation forecast']][mask_date_pred].values)\n",
    "\n",
    "    past_observed_mask = torch.ones(context_length)\n",
    "\n",
    "    Dataset_['past_values'].append(past_values)\n",
    "    Dataset_['future_values'].append(future_values)\n",
    "    Dataset_['past_time_features'].append(past_time_features)\n",
    "    Dataset_['future_time_features'].append(future_time_features)\n",
    "    Dataset_['past_observed_mask'].append(past_observed_mask)\n",
    "\n",
    "Dataset_['past_values'] = torch.stack(Dataset_['past_values']).to(dtype=torch.float32)\n",
    "Dataset_['future_values'] = torch.stack(Dataset_['future_values']).to(dtype=torch.float32)\n",
    "Dataset_['past_time_features'] = torch.stack(Dataset_['past_time_features']).to(dtype=torch.float32)\n",
    "Dataset_['future_time_features'] = torch.stack(Dataset_['future_time_features']).to(dtype=torch.float32)\n",
    "Dataset_['past_observed_mask'] = torch.stack(Dataset_['past_observed_mask']).to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([336, 720, 4])\n",
      "torch.Size([336, 720])\n",
      "torch.Size([336, 720])\n",
      "torch.Size([336, 24, 4])\n",
      "torch.Size([336, 24])\n"
     ]
    }
   ],
   "source": [
    "print(Dataset_['past_time_features'].shape)\n",
    "print(Dataset_['past_values'].shape)\n",
    "print(Dataset_['past_observed_mask'].shape)\n",
    "print(Dataset_['future_time_features'].shape)\n",
    "print(Dataset_['future_values'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([720, 4])\n",
      "torch.Size([720])\n",
      "torch.Size([720])\n",
      "torch.Size([24, 4])\n",
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "print(past_time_features.shape)\n",
    "print(past_values.shape)\n",
    "print(past_observed_mask.shape)\n",
    "\n",
    "print(future_time_features.shape)\n",
    "print(future_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[38.6000, 36.5500, 32.3200,  ..., 30.4300, 29.2800, 23.6100],\n",
       "        [31.9800, 30.5000, 28.7900,  ..., 28.7400, 24.1200, 14.7100],\n",
       "        [30.7500, 29.0300, 24.9600,  ..., 17.2400, 28.5600, 23.1400],\n",
       "        [32.0500, 30.1400, 28.5500,  ..., 23.8700, 17.3800, 15.9200],\n",
       "        [32.2800, 31.1800, 30.1000,  ..., 27.1300, 24.7600, 20.7900],\n",
       "        [29.0000, 29.0800, 27.7200,  ..., 30.3600, 32.4000, 25.4400]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_['past_values'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initializing a Time Series Transformer configuration with 24 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=24, context_length=24*29, input_size=1, output_size=1, num_time_features=4)\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input length 720 and time feature lengths 737 does not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# during training, one provides both past and future values\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# as well as possible additional features\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m      4\u001b[0m     past_values\u001b[39m=\u001b[39;49mDataset_[\u001b[39m'\u001b[39;49m\u001b[39mpast_values\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      5\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mDataset_[\u001b[39m'\u001b[39;49m\u001b[39mpast_time_features\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      6\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mDataset_[\u001b[39m'\u001b[39;49m\u001b[39mpast_observed_mask\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      7\u001b[0m     future_values\u001b[39m=\u001b[39;49mDataset_[\u001b[39m'\u001b[39;49m\u001b[39mfuture_values\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      8\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mDataset_[\u001b[39m'\u001b[39;49m\u001b[39mfuture_time_features\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1603\u001b[0m, in \u001b[0;36mTimeSeriesTransformerForPrediction.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[39mif\u001b[39;00m future_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1601\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1603\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1604\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   1605\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   1606\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   1607\u001b[0m     static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   1608\u001b[0m     static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   1609\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m   1610\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features,\n\u001b[1;32m   1611\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1612\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1613\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1614\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1615\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1616\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1617\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1618\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1619\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1620\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1621\u001b[0m )\n\u001b[1;32m   1623\u001b[0m prediction_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1424\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1421\u001b[0m use_cache \u001b[39m=\u001b[39m use_cache \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_cache\n\u001b[1;32m   1422\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1424\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_network_inputs(\n\u001b[1;32m   1425\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   1426\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   1427\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   1428\u001b[0m     static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   1429\u001b[0m     static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   1430\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m   1431\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features,\n\u001b[1;32m   1432\u001b[0m )\n\u001b[1;32m   1434\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1435\u001b[0m     enc_input \u001b[39m=\u001b[39m transformer_inputs[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcontext_length, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1349\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[0;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[1;32m   1346\u001b[0m reshaped_lagged_sequence \u001b[39m=\u001b[39m lagged_sequence\u001b[39m.\u001b[39mreshape(lags_shape[\u001b[39m0\u001b[39m], lags_shape[\u001b[39m1\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   1348\u001b[0m \u001b[39mif\u001b[39;00m reshaped_lagged_sequence\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m time_feat\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m-> 1349\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1350\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput length \u001b[39m\u001b[39m{\u001b[39;00mreshaped_lagged_sequence\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m and time feature lengths \u001b[39m\u001b[39m{\u001b[39;00mtime_feat\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m does not match\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1351\u001b[0m     )\n\u001b[1;32m   1353\u001b[0m \u001b[39m# transformer inputs\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m transformer_inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((reshaped_lagged_sequence, features), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: input length 720 and time feature lengths 737 does not match"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=Dataset_['past_values'],\n",
    "    past_time_features=Dataset_['past_time_features'],\n",
    "    past_observed_mask=Dataset_['past_observed_mask'],\n",
    "    future_values=Dataset_['future_values'],\n",
    "    future_time_features=Dataset_['future_time_features']\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=Dataset_['past_values'],\n",
    "    past_time_features=Dataset_['future_time_features'],\n",
    "    past_observed_mask=Dataset_['past_observed_mask'],\n",
    "    future_time_features=Dataset_['future_time_features']\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -7.5163, -63.3271,   2.6899, -16.8701,  -2.7818,  -3.5425,  14.8743,\n",
       "           9.1403,  -4.4051,  12.6202,   7.6990, -19.4491, -16.7331,  15.3230,\n",
       "          -9.7587,  -0.2657,  17.9799, -12.4463,   5.1261,  11.6024,   9.9855,\n",
       "         -22.2234,   5.5988,  13.4501],\n",
       "        [ -9.2073,  -8.1139,  12.3300,   6.4870,  17.6020,  -4.9579, -17.7479,\n",
       "          22.4583,  10.6285,   1.9875,  13.6067,  -0.3630,   6.9221,  24.8311,\n",
       "          -2.5540,  11.2675,  -2.2600,  -7.6559,  14.9481,   1.0363,   0.4891,\n",
       "           4.6454, -20.1811,  17.2088],\n",
       "        [-42.6548,  20.2999,  28.9912,  15.0008,  17.3160, -33.3663,   8.9611,\n",
       "           8.9200, -15.7974,   0.3519,   3.6403,  19.3589,  45.0078,   4.0417,\n",
       "          -9.7578,  14.4422,   3.3531,  26.9713,  -0.9255, -13.8006, -34.6340,\n",
       "         -18.0744, -14.3971, -15.8072],\n",
       "        [  4.5246,  -9.2025,  -5.2003,  19.7376,   6.2186,  15.8372,  -6.1950,\n",
       "           2.9575,   2.7287, -14.9392,  37.3583, -11.7959,   0.2238,  28.6783,\n",
       "           2.6541,   2.4881, -12.1210,  -3.2002,  18.3932, -14.2603,  -5.1435,\n",
       "           6.3732,   7.6747, -32.3619],\n",
       "        [  1.9837,   4.7511,  -1.0711,  19.8490,  13.5025,  20.1205,  27.3442,\n",
       "          14.6324,  -0.2370,  19.8809,   0.3248, -11.7516, -11.7733,  25.4746,\n",
       "           2.2246,  18.7465,   3.0657, -13.1691,   9.9623,  -9.7738,   7.7623,\n",
       "           4.0589,   8.1211,  13.0949],\n",
       "        [ 10.6416,  -5.2236,  11.0731, -13.3974,   2.2748,  16.8045, -20.2807,\n",
       "           5.0097,   9.4818,   0.3141, -77.0404, -11.8938, -15.0023,   3.3587,\n",
       "          25.8754,  -1.5109,  23.7693, -23.8018,   0.8444, -22.9648,  17.6446,\n",
       "           2.0275,  -5.1040,  10.5463]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset = dataset.map(lambda x: {'Day of the week': x['Date'].dayofweek})\n",
    "dataset = dataset.map(lambda x: {'Hour of the day': x['Date'].hour})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.filter(lambda x: x['Date'].year < 2019)\n",
    "test_dataset = dataset.filter(lambda x: x['Date'].date() == pd.to_datetime('2019-01-01').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Date', 'Load forecast', 'Generation forecast', 'Price', 'Hour of the day', 'Day of the week'],\n",
       "    num_rows: 17520\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "date = train_dataset['Date'][24*30].date()\n",
    "\n",
    "past_values_all = train_dataset.filter(lambda x: x['Date'].date() < date)\n",
    "past_observed_mask = torch.ones(24*30)\n",
    "#past_observed_mask[-24:,-1] = 0\n",
    "past_time_features = torch.tensor(list(zip(past_values_all['Day of the week'], past_values_all['Hour of the day'], past_values_all['Load forecast'], past_values_all['Generation forecast'])))\n",
    "past_values = torch.tensor(past_values_all['Price'])\n",
    "\n",
    "\n",
    "\n",
    "future_values_all = train_dataset.filter(lambda x: x['Date'].date() == date)\n",
    "future_values = torch.tensor(future_values_all['Price'])\n",
    "\n",
    "future_time_features = torch.tensor(list(zip(future_values_all['Day of the week'], future_values_all['Hour of the day'], future_values_all['Load forecast'], future_values_all['Generation forecast'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 1, 31)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['Date'][24*30].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "number_of_days =1\n",
    "for i in range(number_of_days):\n",
    "    date = date + pd.Timedelta(hours=24)\n",
    "    past_values_all_2 = train_dataset.filter(lambda x: date - pd.Timedelta(days = 30) <= x['Date'].date() < date)\n",
    "    past_observed_mask_temp = torch.ones(24*30)\n",
    "    past_observed_mask=torch.cat((past_observed_mask, past_observed_mask_temp), dim=0)#.reshape(i+3, 24*16, 3)\n",
    "    past_time_features = torch.cat((past_time_features, torch.tensor(list(zip(past_values_all_2['Day of the week'], past_values_all_2['Hour of the day'], past_values_all_2['Load forecast'], past_values_all_2['Generation forecast'])))))#.reshape(i+3, 24*16, 2)\n",
    "    past_values = torch.cat((past_values, torch.tensor(past_values_all_2['Price'])))#.reshape(i+3, 24*16, 3)\n",
    "    \n",
    "    future_values_all_2 = train_dataset.filter(lambda x: x['Date'].date() == date)\n",
    "    future_values = torch.cat((future_values, torch.tensor(future_values_all_2['Price'])))#.reshape(i+3, 24, 3)\n",
    "    future_time_features = torch.cat((future_time_features, torch.tensor(list(zip(future_values_all_2['Day of the week'], future_values_all_2['Hour of the day'], future_values_all_2['Load forecast'], future_values_all_2['Generation forecast'])))))#.reshape(i+3, 24, 2)\n",
    "\n",
    "past_values = past_values.reshape(number_of_days+1, 24*30)\n",
    "past_time_features = past_time_features.reshape(number_of_days+1, 24*30, 4)\n",
    "past_observed_mask = past_observed_mask.reshape(number_of_days+1, 24*30)\n",
    "\n",
    "future_values = future_values.reshape(number_of_days+1, 24)\n",
    "future_time_features = future_time_features.reshape(number_of_days+1, 24, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 720, 4])\n",
      "torch.Size([2, 720])\n",
      "torch.Size([2, 720])\n",
      "torch.Size([2, 24, 4])\n",
      "torch.Size([2, 24])\n"
     ]
    }
   ],
   "source": [
    "print(past_time_features.shape)\n",
    "print(past_values.shape)\n",
    "print(past_observed_mask.shape)\n",
    "\n",
    "print(future_time_features.shape)\n",
    "print(future_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 55.0000,  53.3000,  52.0000,  50.1800,  54.0000,  70.2000,  86.6600,\n",
       "         101.0000,  90.3400,  89.8000,  89.8200,  82.3600,  82.0200,  90.3600,\n",
       "          89.7500,  90.2000,  95.0000, 104.3300,  90.0000,  83.6900,  60.7700,\n",
       "          59.6200,  59.2000,  54.7100],\n",
       "        [ 54.9900,  51.8100,  48.1600,  40.9100,  50.6800,  61.1000,  72.9300,\n",
       "          78.6400,  79.1100,  79.1100,  78.4400,  76.6400,  75.4700,  72.6100,\n",
       "          69.0600,  64.2100,  70.3100,  76.1000,  77.2000,  70.8100,  59.6000,\n",
       "          62.8500,  55.1000,  41.1100]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction\n",
    "\n",
    "# Initializing a Time Series Transformer configuration with 24 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=24, context_length=24*29+17, input_size=1, output_size=1, num_time_features=4)\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerForPrediction(\n",
       "  (model): TimeSeriesTransformerModel(\n",
       "    (scaler): TimeSeriesMeanScaler()\n",
       "    (encoder): TimeSeriesTransformerEncoder(\n",
       "      (value_embedding): TimeSeriesValueEmbedding(\n",
       "        (value_projection): Linear(in_features=13, out_features=64, bias=False)\n",
       "      )\n",
       "      (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(737, 64)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TimeSeriesTransformerEncoderLayer(\n",
       "          (self_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TimeSeriesTransformerDecoder(\n",
       "      (value_embedding): TimeSeriesValueEmbedding(\n",
       "        (value_projection): Linear(in_features=13, out_features=64, bias=False)\n",
       "      )\n",
       "      (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(737, 64)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TimeSeriesTransformerDecoderLayer(\n",
       "          (self_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): TimeSeriesTransformerAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (parameter_projection): ParameterProjection(\n",
       "    (proj): ModuleList(\n",
       "      (0-2): 3 x Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (domain_map): LambdaLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mTimeSeriesTransformerConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprediction_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcontext_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdistribution_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'student_t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nll'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlags_sequence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscaling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_dynamic_real_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_static_categorical_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_static_real_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_time_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcardinality\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membedding_dimension\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder_ffn_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_ffn_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder_attention_heads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_attention_heads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivation_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gelu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0md_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder_layerdrop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdecoder_layerdrop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattention_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivation_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_parallel_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minit_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "This is the configuration class to store the configuration of a [`TimeSeriesTransformerModel`]. It is used to\n",
      "instantiate a Time Series Transformer model according to the specified arguments, defining the model architecture.\n",
      "Instantiating a configuration with the defaults will yield a similar configuration to that of the Time Series\n",
      "Transformer\n",
      "[huggingface/time-series-transformer-tourism-monthly](https://huggingface.co/huggingface/time-series-transformer-tourism-monthly)\n",
      "architecture.\n",
      "\n",
      "Configuration objects inherit from [`PretrainedConfig`] can be used to control the model outputs. Read the\n",
      "documentation from [`PretrainedConfig`] for more information.\n",
      "\n",
      "Args:\n",
      "    prediction_length (`int`):\n",
      "        The prediction length for the decoder. In other words, the prediction horizon of the model. This value is\n",
      "        typically dictated by the dataset and we recommend to set it appropriately.\n",
      "    context_length (`int`, *optional*, defaults to `prediction_length`):\n",
      "        The context length for the encoder. If `None`, the context length will be the same as the\n",
      "        `prediction_length`.\n",
      "    distribution_output (`string`, *optional*, defaults to `\"student_t\"`):\n",
      "        The distribution emission head for the model. Could be either \"student_t\", \"normal\" or \"negative_binomial\".\n",
      "    loss (`string`, *optional*, defaults to `\"nll\"`):\n",
      "        The loss function for the model corresponding to the `distribution_output` head. For parametric\n",
      "        distributions it is the negative log likelihood (nll) - which currently is the only supported one.\n",
      "    input_size (`int`, *optional*, defaults to 1):\n",
      "        The size of the target variable which by default is 1 for univariate targets. Would be > 1 in case of\n",
      "        multivariate targets.\n",
      "    scaling (`string` or `bool`, *optional* defaults to `\"mean\"`):\n",
      "        Whether to scale the input targets via \"mean\" scaler, \"std\" scaler or no scaler if `None`. If `True`, the\n",
      "        scaler is set to \"mean\".\n",
      "    lags_sequence (`list[int]`, *optional*, defaults to `[1, 2, 3, 4, 5, 6, 7]`):\n",
      "        The lags of the input time series as covariates often dictated by the frequency of the data. Default is\n",
      "        `[1, 2, 3, 4, 5, 6, 7]` but we recommend to change it based on the dataset appropriately.\n",
      "    num_time_features (`int`, *optional*, defaults to 0):\n",
      "        The number of time features in the input time series.\n",
      "    num_dynamic_real_features (`int`, *optional*, defaults to 0):\n",
      "        The number of dynamic real valued features.\n",
      "    num_static_categorical_features (`int`, *optional*, defaults to 0):\n",
      "        The number of static categorical features.\n",
      "    num_static_real_features (`int`, *optional*, defaults to 0):\n",
      "        The number of static real valued features.\n",
      "    cardinality (`list[int]`, *optional*):\n",
      "        The cardinality (number of different values) for each of the static categorical features. Should be a list\n",
      "        of integers, having the same length as `num_static_categorical_features`. Cannot be `None` if\n",
      "        `num_static_categorical_features` is > 0.\n",
      "    embedding_dimension (`list[int]`, *optional*):\n",
      "        The dimension of the embedding for each of the static categorical features. Should be a list of integers,\n",
      "        having the same length as `num_static_categorical_features`. Cannot be `None` if\n",
      "        `num_static_categorical_features` is > 0.\n",
      "    d_model (`int`, *optional*, defaults to 64):\n",
      "        Dimensionality of the transformer layers.\n",
      "    encoder_layers (`int`, *optional*, defaults to 2):\n",
      "        Number of encoder layers.\n",
      "    decoder_layers (`int`, *optional*, defaults to 2):\n",
      "        Number of decoder layers.\n",
      "    encoder_attention_heads (`int`, *optional*, defaults to 2):\n",
      "        Number of attention heads for each attention layer in the Transformer encoder.\n",
      "    decoder_attention_heads (`int`, *optional*, defaults to 2):\n",
      "        Number of attention heads for each attention layer in the Transformer decoder.\n",
      "    encoder_ffn_dim (`int`, *optional*, defaults to 32):\n",
      "        Dimension of the \"intermediate\" (often named feed-forward) layer in encoder.\n",
      "    decoder_ffn_dim (`int`, *optional*, defaults to 32):\n",
      "        Dimension of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
      "    activation_function (`str` or `function`, *optional*, defaults to `\"gelu\"`):\n",
      "        The non-linear activation function (function or string) in the encoder and decoder. If string, `\"gelu\"` and\n",
      "        `\"relu\"` are supported.\n",
      "    dropout (`float`, *optional*, defaults to 0.1):\n",
      "        The dropout probability for all fully connected layers in the encoder, and decoder.\n",
      "    encoder_layerdrop (`float`, *optional*, defaults to 0.1):\n",
      "        The dropout probability for the attention and fully connected layers for each encoder layer.\n",
      "    decoder_layerdrop (`float`, *optional*, defaults to 0.1):\n",
      "        The dropout probability for the attention and fully connected layers for each decoder layer.\n",
      "    attention_dropout (`float`, *optional*, defaults to 0.1):\n",
      "        The dropout probability for the attention probabilities.\n",
      "    activation_dropout (`float`, *optional*, defaults to 0.1):\n",
      "        The dropout probability used between the two layers of the feed-forward networks.\n",
      "    num_parallel_samples (`int`, *optional*, defaults to 100):\n",
      "        The number of samples to generate in parallel for each time step of inference.\n",
      "    init_std (`float`, *optional*, defaults to 0.02):\n",
      "        The standard deviation of the truncated normal weight initialization distribution.\n",
      "    use_cache (`bool`, *optional*, defaults to `True`):\n",
      "        Whether to use the past key/values attentions (if applicable to the model) to speed up decoding.\n",
      "\n",
      "    Example:\n",
      "\n",
      "```python\n",
      ">>> from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
      "\n",
      ">>> # Initializing a Time Series Transformer configuration with 12 time steps for prediction\n",
      ">>> configuration = TimeSeriesTransformerConfig(prediction_length=12)\n",
      "\n",
      ">>> # Randomly initializing a model (with random weights) from the configuration\n",
      ">>> model = TimeSeriesTransformerModel(configuration)\n",
      "\n",
      ">>> # Accessing the model configuration\n",
      ">>> configuration = model.config\n",
      "```\n",
      "\u001b[0;31mFile:\u001b[0m           ~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/configuration_time_series_transformer.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "TimeSeriesTransformerConfig?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1).detach().cpu()\n",
    "df_pred = pd.DataFrame(mean_prediction.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('/home/infres/dfitton-21/pfr/fil_rouge/forecasts/transformer_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_prediction\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "mean_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.0000, 53.3000, 52.0000,  ..., 59.6200, 59.2000, 54.7100],\n",
       "        [54.9900, 51.8100, 48.1600,  ..., 62.8500, 55.1000, 41.1100],\n",
       "        [38.7400, 36.9400, 32.3000,  ..., 40.8000, 42.1200, 39.8700],\n",
       "        ...,\n",
       "        [29.5000, 28.9400, 29.9000,  ..., 36.6800, 33.2600, 33.5400],\n",
       "        [32.8500, 30.7200, 31.0300,  ..., 36.7200, 31.1600, 30.4100],\n",
       "        [29.5000, 29.1700, 29.5900,  ..., 38.5100, 38.2400, 29.4300]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214339"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"kashif/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 61, 2])\n",
      "torch.Size([64, 61])\n",
      "torch.Size([64, 61])\n",
      "torch.Size([64, 24, 2])\n",
      "torch.Size([64, 24])\n"
     ]
    }
   ],
   "source": [
    "print(batch['past_time_features'].shape)\n",
    "print(batch['past_values'].shape)\n",
    "print(batch['past_observed_mask'].shape)\n",
    "\n",
    "print(batch['future_time_features'].shape)\n",
    "print(batch['future_values'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2273,  2.3541],\n",
       "        [ 0.3182,  2.3560],\n",
       "        [ 0.4091,  2.3579],\n",
       "        [ 0.5000,  2.3598],\n",
       "        [-0.5000,  2.3617],\n",
       "        [-0.4091,  2.3636],\n",
       "        [-0.3182,  2.3655],\n",
       "        [-0.2273,  2.3674],\n",
       "        [-0.1364,  2.3692],\n",
       "        [-0.0455,  2.3711],\n",
       "        [ 0.0455,  2.3729],\n",
       "        [ 0.1364,  2.3747],\n",
       "        [ 0.2273,  2.3766],\n",
       "        [ 0.3182,  2.3784],\n",
       "        [ 0.4091,  2.3802],\n",
       "        [ 0.5000,  2.3820],\n",
       "        [-0.5000,  2.3838],\n",
       "        [-0.4091,  2.3856],\n",
       "        [-0.3182,  2.3874],\n",
       "        [-0.2273,  2.3892],\n",
       "        [-0.1364,  2.3909],\n",
       "        [-0.0455,  2.3927],\n",
       "        [ 0.0455,  2.3945],\n",
       "        [ 0.1364,  2.3962]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['future_time_features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 187kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 151k/151k [00:00<00:00, 552kB/s]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerForPrediction\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"kashif/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction.from_pretrained(\n",
    "    \"huggingface/time-series-transformer-tourism-monthly\"\n",
    ")\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 24])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 24])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['future_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2474)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(mean_prediction - batch['future_values'])/batch['future_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13825.9795)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['future_values'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction\n",
    "import numpy as np\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "                 Date  Load forecast  Generation forecast  Price   \n",
      "0 2017-01-01 00:00:00        73650.0              69539.0  58.23  \\\n",
      "1 2017-01-01 01:00:00        72350.0              67376.0  51.95   \n",
      "2 2017-01-01 02:00:00        68750.0              65412.0  47.27   \n",
      "3 2017-01-01 03:00:00        65900.0              64557.0  45.49   \n",
      "4 2017-01-01 04:00:00        65000.0              64552.0  44.50   \n",
      "\n",
      "   Hour of the day  Day of the week  Day of the year  Year  Month of the year  \n",
      "0                0                6                1  2017                  1  \n",
      "1                1                6                1  2017                  1  \n",
      "2                2                6                1  2017                  1  \n",
      "3                3                6                1  2017                  1  \n",
      "4                4                6                1  2017                  1  \n",
      "csv done\n",
      "torch.Size([1, 17280, 7]) torch.float64\n",
      "torch.Size([1, 17280]) torch.float64\n",
      "torch.Size([1, 17280]) torch.float64\n",
      "torch.Size([1, 24, 7]) torch.float64\n",
      "torch.Size([1, 24]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Test py\n",
    "\n",
    "\n",
    "#device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "context =720\n",
    "\n",
    "df = pd.read_csv(\"/home/infres/dfitton-21/pfr/fil_rouge/examples/datasets/EPEX_FR 2.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Hour of the day'] = df['Date'].dt.hour\n",
    "df['Day of the week'] = df['Date'].dt.dayofweek\n",
    "df['Day of the year'] = df['Date'].dt.dayofyear\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month of the year'] = df['Date'].dt.month\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"/home/infres/dfitton-21/pfr/fil_rouge/examples/datasets/EPEX_FR_2_transformer.csv\")\n",
    "print('csv done')\n",
    "nb_time_feat = 7\n",
    "\n",
    "train_df = df[df['Year'] < 2021]\n",
    "test_df = df[df['Date'].dt.date == pd.to_datetime('2021-01-01').date()]\n",
    "\n",
    "date = train_df['Date'].iloc[24*context].date()\n",
    "\n",
    "past_values_all = train_df[train_df['Date'].dt.date < date]\n",
    "past_observed_mask = np.ones(24*context).reshape(1, -1)\n",
    "past_time_features = np.array(past_values_all[['Day of the week', 'Hour of the day', 'Day of the year', 'Year', 'Month of the year', 'Load forecast', 'Generation forecast']]).reshape(1, -1, nb_time_feat)#.astype(np.float64)\n",
    "past_values = np.array(past_values_all['Price']).reshape(1, -1)#.astype(np.float64)\n",
    "\n",
    "future_values_all = train_df[train_df['Date'].dt.date == date]\n",
    "future_values = np.array(future_values_all['Price']).reshape(1, -1)#.astype(np.float64)\n",
    "future_time_features = np.array(future_values_all[['Day of the week', 'Hour of the day', 'Day of the year', 'Year', 'Month of the year', 'Load forecast', 'Generation forecast']]).reshape(1, -1, nb_time_feat)#.astype(np.float64)\n",
    "\n",
    "past_values = torch.tensor(past_values).double().to(device)\n",
    "past_time_features = torch.tensor(past_time_features).double().to(device)\n",
    "past_observed_mask = torch.tensor(past_observed_mask).double().to(device)\n",
    "future_values = torch.tensor(future_values).double().to(device)\n",
    "future_time_features = torch.tensor(future_time_features).double().to(device)\n",
    "\n",
    "#number_of_days =0\n",
    "#for i in range(number_of_days):\n",
    "#date = date + pd.Timedelta(hours=24)\n",
    "#past_values_all_2 = train_dataset.filter(lambda x: date - pd.Timedelta(days = context) <= x['Date'].date() < date)\n",
    "#past_observed_mask_temp = torch.ones(24*context)\n",
    "#past_observed_mask=torch.cat((past_observed_mask, past_observed_mask_temp), dim=0)#.reshape(i+3, 24*context, nb_time_feat)\n",
    "#past_time_features = torch.cat((past_time_features, torch.tensor(list(zip(past_values_all_2['Day of the week'], past_values_all_2['Hour of the day'],past_values_all_2['Day of the year'], past_values_all_2['Year'], past_values_all_2['Month of the year'], past_values_all_2['Load forecast'], past_values_all_2['Generation forecast'])))))#.reshape(i+3, 24*16, 2)\n",
    "#past_values = torch.cat((past_values, torch.tensor(past_values_all_2['Price'])))#.reshape(i+3, 24*context, 3)\n",
    "\n",
    "#future_values_all_2 = train_dataset.filter(lambda x: x['Date'].date() == date)\n",
    "#future_values = torch.cat((future_values, torch.tensor(future_values_all_2['Price'])))#.reshape(i+3, 24, nb_time_feat)\n",
    "#future_time_features = torch.cat((future_time_features, torch.tensor(list(zip(future_values_all_2['Day of the week'], future_values_all_2['Hour of the day'],future_values_all_2['Day of the year'], future_values_all_2['Year'], future_values_all_2['Month of the year'], future_values_all_2['Load forecast'], future_values_all_2['Generation forecast'])))))#.reshape(i+3, 24, 2)\n",
    "\n",
    "#past_values = past_values.reshape(number_of_days+1, 24*context)\n",
    "#past_time_features = past_time_features.reshape(number_of_days+1, 24*context, nb_time_feat)\n",
    "#past_observed_mask = past_observed_mask.reshape(number_of_days+1, 24*context)\n",
    "\n",
    "#future_values = future_values.reshape(number_of_days+1, 24)\n",
    "#future_time_features = future_time_features.reshape(number_of_days+1, 24, nb_time_feat)\n",
    "print(past_time_features.shape, past_time_features.dtype)\n",
    "print(past_values.shape, past_values.dtype)\n",
    "print(past_observed_mask.shape, past_observed_mask.dtype)\n",
    "\n",
    "print(future_time_features.shape, future_time_features.dtype)\n",
    "print(future_values.shape, future_values.dtype)\n",
    "\n",
    "#past_time_features = past_time_features.to(device)\n",
    "#past_observed_mask = past_observed_mask.to(device)\n",
    "#future_values = future_values.to(device)\n",
    "#future_time_features = future_time_features.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[58.2300, 51.9500, 47.2700,  ..., 46.2200, 41.2700, 38.0200]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array(past_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[39m# during training, one provides both past and future values\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# as well as possible additional features\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m     17\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m     18\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m     19\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m     20\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m     21\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     25\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1603\u001b[0m, in \u001b[0;36mTimeSeriesTransformerForPrediction.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[39mif\u001b[39;00m future_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1601\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1603\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1604\u001b[0m     past_values\u001b[39m=\u001b[39;49mpast_values,\n\u001b[1;32m   1605\u001b[0m     past_time_features\u001b[39m=\u001b[39;49mpast_time_features,\n\u001b[1;32m   1606\u001b[0m     past_observed_mask\u001b[39m=\u001b[39;49mpast_observed_mask,\n\u001b[1;32m   1607\u001b[0m     static_categorical_features\u001b[39m=\u001b[39;49mstatic_categorical_features,\n\u001b[1;32m   1608\u001b[0m     static_real_features\u001b[39m=\u001b[39;49mstatic_real_features,\n\u001b[1;32m   1609\u001b[0m     future_values\u001b[39m=\u001b[39;49mfuture_values,\n\u001b[1;32m   1610\u001b[0m     future_time_features\u001b[39m=\u001b[39;49mfuture_time_features,\n\u001b[1;32m   1611\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1612\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1613\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1614\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1615\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1616\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1617\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1618\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1619\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1620\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1621\u001b[0m )\n\u001b[1;32m   1623\u001b[0m prediction_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1436\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1435\u001b[0m     enc_input \u001b[39m=\u001b[39m transformer_inputs[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcontext_length, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[0;32m-> 1436\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1437\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49menc_input,\n\u001b[1;32m   1438\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1439\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1440\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1441\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1442\u001b[0m     )\n\u001b[1;32m   1443\u001b[0m \u001b[39m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1444\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:912\u001b[0m, in \u001b[0;36mTimeSeriesTransformerEncoder.forward\u001b[0;34m(self, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    907\u001b[0m output_hidden_states \u001b[39m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     output_hidden_states \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moutput_hidden_states\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 912\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_embedding(inputs_embeds)\n\u001b[1;32m    913\u001b[0m embed_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions(inputs_embeds\u001b[39m.\u001b[39msize())\n\u001b[1;32m    915\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_embedding(hidden_states \u001b[39m+\u001b[39m embed_pos)\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:301\u001b[0m, in \u001b[0;36mTimeSeriesValueEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_projection(x)\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "# Initializing a Time Series Transformer configuration with 24 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=24, context_length=24*(context-1)+17, input_size=1, output_size=1, num_time_features=nb_time_feat )\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1).detach().cpu()\n",
    "df_pred = pd.DataFrame(mean_prediction.numpy())\n",
    "\n",
    "df_pred.to_csv('/home/infres/dfitton-21/pfr/fil_rouge/forecasts/transformer_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloggers\u001b[39;00m \u001b[39mimport\u001b[39;00m CSVLogger\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m TransformerEstimator\n\u001b[1;32m     15\u001b[0m dataset \u001b[39m=\u001b[39m get_dataset(\u001b[39m\"\u001b[39m\u001b[39melectricity\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/estimator/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model, Estimator, spec\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m clip, decay, optimizer\n",
      "File \u001b[0;32m~/conda_env/miniconda/envs/frtr2/lib/python3.8/site-packages/estimator/modes.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m TRAIN \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mModeKeys\u001b[39m.\u001b[39mTRAIN\n\u001b[1;32m      4\u001b[0m EVAL \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mModeKeys\u001b[39m.\u001b[39mEVAL\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from datasets import load_dataset\n",
    "\n",
    "from estimator import TransformerEstimator\n",
    "dataset = get_dataset(\"electricity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorianfitton/opt/anaconda3/envs/bgd/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel, TimeSeriesTransformerForPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting making prediction\n",
      "   Unnamed: 0                Date  Load forecast  Generation forecast  Price  \\\n",
      "0           0 2017-01-01 00:00:00        73650.0              69539.0  58.23   \n",
      "1           1 2017-01-01 01:00:00        72350.0              67376.0  51.95   \n",
      "2           2 2017-01-01 02:00:00        68750.0              65412.0  47.27   \n",
      "3           3 2017-01-01 03:00:00        65900.0              64557.0  45.49   \n",
      "4           4 2017-01-01 04:00:00        65000.0              64552.0  44.50   \n",
      "\n",
      "   Hour of the day  Day of the week  Day of the year  Year  Month of the year  \n",
      "0                0                6                1  2017                  1  \n",
      "1                1                6                1  2017                  1  \n",
      "2                2                6                1  2017                  1  \n",
      "3                3                6                1  2017                  1  \n",
      "4                4                6                1  2017                  1  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e521f6e07fd74764b38d3fc949c98029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fa9a210b14420882c4a053e4b65cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73be8dde0ba4ab5ab330dfe011f0888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/35064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77662b3519984479ba17c2624b98060d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/35064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4320, 7])\n",
      "torch.Size([1, 4320])\n",
      "torch.Size([1, 4320])\n",
      "torch.Size([1, 24, 7])\n",
      "torch.Size([1, 24])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/examples/datasets/EPEX_FR_2_transformer.csv\")\n",
    "\n",
    "print(\"Starting making prediction\")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "context =180\n",
    "\n",
    "#df = pd.read_csv(\"/home/infres/dfitton-21/pfr/fil_rouge/examples/datasets/EPEX_FR 2.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "#df['Hour of the day'] = df['Date'].dt.hour\n",
    "#df['Day of the week'] = df['Date'].dt.dayofweek\n",
    "#df['Day of the year'] = df['Date'].dt.dayofyear\n",
    "#df['Year'] = df['Date'].dt.year\n",
    "#df['Month of the year'] = df['Date'].dt.month\n",
    "print(df.head())\n",
    "\n",
    "nb_time_feat = 7\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "#dataset = dataset.map(lambda x: {'Day of the week': x['Date'].dayofweek})\n",
    "#dataset = dataset.map(lambda x: {'Hour of the day': x['Date'].hour})\n",
    "#dataset = dataset.map(lambda x: {'Day of the year': x['Date'].dayofyear})\n",
    "#dataset = dataset.map(lambda x: {'Year': x['Date'].year})\n",
    "#dataset = dataset.map(lambda x: {'Month of the year': x['Date'].month})\n",
    "\n",
    "\n",
    "train_dataset = dataset.filter(lambda x: x['Date'].year < 2021)\n",
    "test_dataset = dataset.filter(lambda x: x['Date'].date() == pd.to_datetime('2021-01-01').date())\n",
    "\n",
    "date = train_dataset['Date'][24*context].date()\n",
    "\n",
    "past_values_all = train_dataset.filter(lambda x: x['Date'].date() < date)\n",
    "past_observed_mask = torch.ones(24*context).reshape(1, -1)\n",
    "#past_observed_mask[-24:,-1] = 0\n",
    "past_time_features = torch.tensor(list(zip(past_values_all['Day of the week'], past_values_all['Hour of the day'],past_values_all['Day of the year'], past_values_all['Year'], past_values_all['Month of the year'] ,past_values_all['Load forecast'], past_values_all['Generation forecast']))).reshape(1, -1, nb_time_feat)\n",
    "past_values = torch.tensor(past_values_all['Price']).reshape(1, -1) \n",
    "\n",
    "\n",
    "\n",
    "future_values_all = train_dataset.filter(lambda x: x['Date'].date() == date)\n",
    "future_values = torch.tensor(future_values_all['Price']).reshape(1, -1)\n",
    "\n",
    "future_time_features = torch.tensor(list(zip(future_values_all['Day of the week'], future_values_all['Hour of the day'], future_values_all['Day of the year'], future_values_all['Year'], future_values_all['Month of the year'],future_values_all['Load forecast'], future_values_all['Generation forecast']))).reshape(1, -1, nb_time_feat)\n",
    "\n",
    "\n",
    "\n",
    "#number_of_days =0\n",
    "#for i in range(number_of_days):\n",
    "#date = date + pd.Timedelta(hours=24)\n",
    "#past_values_all_2 = train_dataset.filter(lambda x: date - pd.Timedelta(days = context) <= x['Date'].date() < date)\n",
    "#past_observed_mask_temp = torch.ones(24*context)\n",
    "#past_observed_mask=torch.cat((past_observed_mask, past_observed_mask_temp), dim=0)#.reshape(i+3, 24*context, nb_time_feat)\n",
    "#past_time_features = torch.cat((past_time_features, torch.tensor(list(zip(past_values_all_2['Day of the week'], past_values_all_2['Hour of the day'],past_values_all_2['Day of the year'], past_values_all_2['Year'], past_values_all_2['Month of the year'], past_values_all_2['Load forecast'], past_values_all_2['Generation forecast'])))))#.reshape(i+3, 24*16, 2)\n",
    "#past_values = torch.cat((past_values, torch.tensor(past_values_all_2['Price'])))#.reshape(i+3, 24*context, 3)\n",
    "\n",
    "#future_values_all_2 = train_dataset.filter(lambda x: x['Date'].date() == date)\n",
    "#future_values = torch.cat((future_values, torch.tensor(future_values_all_2['Price'])))#.reshape(i+3, 24, nb_time_feat)\n",
    "#future_time_features = torch.cat((future_time_features, torch.tensor(list(zip(future_values_all_2['Day of the week'], future_values_all_2['Hour of the day'],future_values_all_2['Day of the year'], future_values_all_2['Year'], future_values_all_2['Month of the year'], future_values_all_2['Load forecast'], future_values_all_2['Generation forecast'])))))#.reshape(i+3, 24, 2)\n",
    "\n",
    "#past_values = past_values.reshape(number_of_days+1, 24*context)\n",
    "#past_time_features = past_time_features.reshape(number_of_days+1, 24*context, nb_time_feat)\n",
    "#past_observed_mask = past_observed_mask.reshape(number_of_days+1, 24*context)\n",
    "\n",
    "#future_values = future_values.reshape(number_of_days+1, 24)\n",
    "#future_time_features = future_time_features.reshape(number_of_days+1, 24, nb_time_feat)\n",
    "print(past_time_features.shape)\n",
    "print(past_values.shape)\n",
    "print(past_observed_mask.shape)\n",
    "\n",
    "print(future_time_features.shape)\n",
    "print(future_values.shape)\n",
    "\n",
    "past_values = past_values.to(device)\n",
    "past_time_features = past_time_features.to(device)\n",
    "past_observed_mask = past_observed_mask.to(device)\n",
    "future_values = future_values.to(device)\n",
    "future_time_features = future_time_features.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initializing a Time Series Transformer configuration with 24 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=24, context_length=24*(context-1)+17, input_size=1, output_size=1, num_time_features=nb_time_feat )\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    future_time_features=future_time_features\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1).detach().cpu()\n",
    "df_pred = pd.DataFrame(mean_prediction.numpy())\n",
    "\n",
    "df_pred.to_csv('/Users/dorianfitton/Library/Mobile Documents/com~apple~CloudDocs/Documents/Cours_Télécom/fil_rouge/fil_rouge.nosync/forecasts/transformer_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frtr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
